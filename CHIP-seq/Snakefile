# ChIP-seq Analysis Pipeline (Snakemake)
# Based on Peng-He-Lab/Luo_2025_piRNA repository
# This workflow processes ChIP-seq data from raw FASTQ to BigWig visualization

# Load configuration
configfile: "config.yaml"

import os
import sys

# ==============================================================================
# PATCHED BOWTIE CONFIGURATION
# ==============================================================================
# Use patched Bowtie with --sam-nh flag support (Henry's modified version)
# If patched bowtie exists in Shared/Scripts/bin/, use it; otherwise fall back to conda bowtie

# Get the directory where this Snakefile is located
# Snakemake sets __file__ to the Snakefile path when it loads it
# However, if that doesn't work, we'll use the workflow directory or current working directory
try:
    SNAKEFILE_PATH = os.path.abspath(__file__)
    # Sanity check: if __file__ points to a weird location (like conda env), use fallback
    if 'site-packages' in SNAKEFILE_PATH or 'lib/python' in SNAKEFILE_PATH:
        # __file__ is pointing to a conda environment, use fallback
        raise ValueError("__file__ points to conda environment")
except (NameError, ValueError):
    # Fallback: use current working directory (Snakemake runs from CHIP-seq/)
    # or try to find the Snakefile relative to where we are
    cwd = os.getcwd()
    if os.path.exists(os.path.join(cwd, "Snakefile")):
        SNAKEFILE_PATH = os.path.join(cwd, "Snakefile")
    else:
        # Last resort: assume we're in CHIP-seq and Snakefile is here
        SNAKEFILE_PATH = os.path.abspath("Snakefile")

SNAKEFILE_DIR = os.path.dirname(SNAKEFILE_PATH)
# Go up one level from CHIP-seq/ to project root
PROJECT_ROOT = os.path.dirname(SNAKEFILE_DIR)
PATCHED_BOWTIE_DIR = os.path.join(PROJECT_ROOT, "Shared", "Scripts", "bin")
PATCHED_BOWTIE = os.path.join(PATCHED_BOWTIE_DIR, "bowtie")
PATCHED_BOWTIE_BUILD = os.path.join(PATCHED_BOWTIE_DIR, "bowtie-build")

# Check if patched bowtie exists, otherwise use system bowtie (from conda)
if os.path.exists(PATCHED_BOWTIE) and os.access(PATCHED_BOWTIE, os.X_OK):
    BOWTIE_CMD = PATCHED_BOWTIE
    BOWTIE_BUILD_CMD = PATCHED_BOWTIE_BUILD
    print(f"INFO: Using patched Bowtie: {BOWTIE_CMD}", file=sys.stderr)
else:
    BOWTIE_CMD = "bowtie"
    BOWTIE_BUILD_CMD = "bowtie-build"
    print(f"WARNING: Patched Bowtie not found at {PATCHED_BOWTIE}, using system bowtie", file=sys.stderr)

# ==============================================================================
# OLD SAMTOOLS VERSIONS CONFIGURATION
# ==============================================================================
# Use exact same samtools versions as original pipeline:
# - samtools-0.1.8 for 'samtools view' operations
# - samtools-0.1.16 for 'samtools sort', 'samtools index', 'samtools rmdup'
SAMTOOLS_018_DIR = os.path.join(PATCHED_BOWTIE_DIR, "samtools-0.1.8")
SAMTOOLS_016_DIR = os.path.join(PATCHED_BOWTIE_DIR, "samtools-0.1.16")
SAMTOOLS_018 = os.path.join(SAMTOOLS_018_DIR, "samtools")
SAMTOOLS_016 = os.path.join(SAMTOOLS_016_DIR, "samtools")

# Check if old samtools versions exist
if os.path.exists(SAMTOOLS_018) and os.access(SAMTOOLS_018, os.X_OK):
    SAMTOOLS_VIEW_CMD = SAMTOOLS_018
    print(f"INFO: Using samtools-0.1.8 for view operations: {SAMTOOLS_VIEW_CMD}", file=sys.stderr)
else:
    SAMTOOLS_VIEW_CMD = "samtools"
    print(f"WARNING: samtools-0.1.8 not found at {SAMTOOLS_018}, using system samtools", file=sys.stderr)

if os.path.exists(SAMTOOLS_016) and os.access(SAMTOOLS_016, os.X_OK):
    SAMTOOLS_SORT_CMD = SAMTOOLS_016
    SAMTOOLS_INDEX_CMD = SAMTOOLS_016
    SAMTOOLS_RMDUP_CMD = SAMTOOLS_016
    print(f"INFO: Using samtools-0.1.16 for sort/index/rmdup: {SAMTOOLS_SORT_CMD}", file=sys.stderr)
else:
    SAMTOOLS_SORT_CMD = "samtools"
    SAMTOOLS_INDEX_CMD = "samtools"
    SAMTOOLS_RMDUP_CMD = "samtools"
    print(f"WARNING: samtools-0.1.16 not found at {SAMTOOLS_016}, using system samtools", file=sys.stderr)

# ==============================================================================
# BACKWARD COMPATIBILITY LAYER
# ==============================================================================
# Support both old-style (references section) and new-style (genome section)
# configuration formats. If 'genome' section exists, use it; otherwise fall
# back to old 'references' section.
# ==============================================================================

if "genome" in config:
    # New format - use genome-agnostic configuration
    GENOME_VERSION = config["genome"]["version"]
    GENOME_SPECIES = config["genome"]["species"]
    
    # Expand path templates with genome version
    GENOME_FASTA = config["genome"]["fasta"].format(version=GENOME_VERSION)
    GENOME_BOWTIE_INDEX = config["genome"]["bowtie_index"].format(version=GENOME_VERSION)
    GENOME_CHROM_SIZES = config["genome"]["chrom_sizes"].format(version=GENOME_VERSION)
    
    # Optional blacklist file (not all genomes have this)
    if "blacklist" in config["genome"] and config["genome"]["blacklist"]:
        GENOME_BLACKLIST = config["genome"]["blacklist"].format(version=GENOME_VERSION)
    else:
        GENOME_BLACKLIST = None
    
    # GTF file for annotations
    if "gtf" in config["genome"]:
        GENOME_GTF = config["genome"]["gtf"].format(version=GENOME_VERSION)
    else:
        GENOME_GTF = None
else:
    # Old format - use legacy dm6-specific configuration
    GENOME_VERSION = "dm6"
    GENOME_SPECIES = "drosophila"
    GENOME_FASTA = config["references"]["dm6_fasta"]
    GENOME_BLACKLIST = config["references"]["dm6_blacklist"]
    GENOME_CHROM_SIZES = config["references"]["dm6_chrom_sizes"]
    GENOME_BOWTIE_INDEX = config["references"]["dm6_bowtie_index"]
    GENOME_GTF = None

# Legacy variable names for backward compatibility with existing code
DM6_REFERENCE = GENOME_FASTA
DM6_BLACKLIST = GENOME_BLACKLIST
DM6_CHROM_SIZES = GENOME_CHROM_SIZES
DM6_BOWTIE_INDEX = GENOME_BOWTIE_INDEX

# Helper function for transposon region lookup
def get_transposon_region(wildcards):
    """Get transposon region string from config based on wildcards.
    Converts format from chr:start-end to chr:start:end for bamCoverage compatibility.
    Note: config is accessed from global scope since params functions don't receive it automatically.
    """
    genome_version = config["genome"]["version"]
    transposon = wildcards.transposon
    region = config["genome"]["transposon_regions"][genome_version][transposon]
    # Convert chr:start-end format to chr:start:end format for bamCoverage
    if "-" in region and ":" in region:
        # Format: chr:start-end -> chr:start:end
        parts = region.split(":")
        if len(parts) == 2:
            chrom, rest = parts
            if "-" in rest:
                start, end = rest.split("-")
                return f"{chrom}:{start}:{end}"
    return region

# Extract configuration values
CHIP_SAMPLE = config["samples"]["chip"]
INPUT_SAMPLE = config["samples"]["input"]
SAMPLES = [CHIP_SAMPLE, INPUT_SAMPLE]

# Paths
RESULTS_DIR = config["output"]["results_dir"]
INPUT_DATA_DIR = config["input_data"]["data_dir"]

# Scripts
TRIMFASTQ_SCRIPT = config["scripts"]["trimfastq"]
MAKEWIGGLE_SCRIPT = config["scripts"]["makewiggle"]

# Vector files
VECTOR_42AB_INDEX = config["references"]["vector_42ab_index"]
VECTOR_42AB_REF = config["references"]["vector_42ab_fasta"]
VECTOR_20A_INDEX = config["references"]["vector_20a_index"]
VECTOR_20A_REF = config["references"]["vector_20a_fasta"]

# Adapter files
ADAPTERS_FILE = config["references"]["adapters_file"]

# Analysis parameters
BIN_SIZES = config["analysis"]["bin_sizes"]
TRANSPOSON_BIN_SIZES = config["analysis"]["transposon_bin_sizes"]

# Main rule - defines all outputs
rule all:
    input:
        # Quality control outputs
        expand(f"{RESULTS_DIR}/fastqc_trimmed/{{sample}}.alltrimmed_fastqc.html", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/trimmed_50bp/{{sample}}.fastq", sample=SAMPLES),

        # Genome mapping outputs
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.sorted_final.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.sorted_final.bam.bai", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.no_mito_sorted.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.rmdup.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.rmdup.bam.bai", sample=SAMPLES),

        # Vector mapping outputs
        expand(f"{RESULTS_DIR}/vector_mapping/{{sample}}.vectoronly.dup.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/vector_mapping/{{sample}}.vectoronly.dup.bam.bai", sample=SAMPLES),

        # Signal outputs
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.bigwig", sample=SAMPLES),

        # Enrichment analysis
        f"{RESULTS_DIR}/enrichment/Panx_GLKD_ChIP_input_1st_S1_R1_001_vs_Panx_GLKD_ChIP_input_2nd_S4_R1_001.enrichment.bigwig",

        # Coverage analysis
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.Minus.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.Plus.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        # Temporarily disabled chopped files due to disk space issues
        # expand(
        #     RESULTS_DIR + "/coverage/{sample}.{binsize}.Minus.bg4.chopped.bg4",
        #     sample=SAMPLES,
        #     binsize=BIN_SIZES,
        # ),
        # expand(
        #     RESULTS_DIR + "/coverage/{sample}.{binsize}.Plus.bg4.chopped.bg4",
        #     sample=SAMPLES,
        #     binsize=BIN_SIZES,
        # ),

        # Transposon analysis (42AB and 20A)
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.{{transposon}}.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
            transposon=["42AB", "20A"],
        ),
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.{{transposon}}.Minus.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
            transposon=["42AB", "20A"],
        ),
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.{{transposon}}.Plus.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
            transposon=["42AB", "20A"],
        ),

# Index building rules - these generate indexes from source files
rule build_genome_bowtie_index:
    """Build bowtie index for the genome (genome-agnostic)"""
    input:
        genome_fa = GENOME_FASTA
    output:
        index_files = expand(f"{GENOME_BOWTIE_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {GENOME_BOWTIE_INDEX})
        {BOWTIE_BUILD_CMD} {input.genome_fa} {GENOME_BOWTIE_INDEX}
        """

rule build_vector_42AB_index:
    input:
        vector_fa = VECTOR_42AB_REF
    output:
        index_files = expand(f"{VECTOR_42AB_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {VECTOR_42AB_INDEX})
        {BOWTIE_BUILD_CMD} {input.vector_fa} {VECTOR_42AB_INDEX}
        """

rule build_vector_20A_index:
    input:
        vector_fa = VECTOR_20A_REF
    output:
        index_files = expand(f"{VECTOR_20A_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {VECTOR_20A_INDEX})
        {BOWTIE_BUILD_CMD} {input.vector_fa} {VECTOR_20A_INDEX}
        """

rule generate_chrom_sizes:
    """Generate chromosome sizes file from genome FASTA (genome-agnostic)"""
    input:
        genome_fa = GENOME_FASTA
    output:
        chrom_sizes = GENOME_CHROM_SIZES
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        mkdir -p $(dirname {output.chrom_sizes})
        {SAMTOOLS_VIEW_CMD} faidx {input.genome_fa}
        cut -f1,2 {input.genome_fa}.fai > {output.chrom_sizes}
        """

# Quality control rules
rule fastqc_raw:
    input:
        fastq = f"{INPUT_DATA_DIR}/{{sample}}.fastq"
    output:
        html = RESULTS_DIR + "/fastqc_raw/{{sample}}_fastqc.html",
        zip = RESULTS_DIR + "/fastqc_raw/{{sample}}_fastqc.zip"
    conda:
        "envs/fastqc.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/fastqc_raw
        fastqc {input.fastq} -o {RESULTS_DIR}/fastqc_raw
        """

rule trim_adapters:
    input:
        fastq = f"{INPUT_DATA_DIR}/{{sample}}.fastq",
        adapters = ADAPTERS_FILE
    output:
        trimmed = RESULTS_DIR + "/trimmed/{sample}.trimmed.fastq"
    conda:
        "envs/cutadapt.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/trimmed
        cutadapt -a file:{input.adapters} -o {output.trimmed} {input.fastq}
        """

rule trimmomatic:
    input:
        fastq = RESULTS_DIR + "/trimmed/{sample}.trimmed.fastq"
    output:
        trimmed = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    conda:
        "envs/trimmomatic.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/trimmomatic
        trimmomatic SE {input.fastq} {output.trimmed} \
            ILLUMINACLIP:{ADAPTERS_FILE}:2:30:10 \
            LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:50
        """

rule fastqc_trimmed:
    input:
        fastq = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    output:
        html = RESULTS_DIR + "/fastqc_trimmed/{sample}.alltrimmed_fastqc.html",
        zip = RESULTS_DIR + "/fastqc_trimmed/{sample}.alltrimmed_fastqc.zip"
    conda:
        "envs/fastqc.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/fastqc_trimmed
        fastqc {input.fastq} -o {RESULTS_DIR}/fastqc_trimmed
        """

rule trim_to_50bp:
    input:
        alltrimmed = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    output:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq"
    conda:
        "envs/python.yaml"
    shell:
        """
        mkdir -p $(dirname {output.trimmed_50bp})
        python {TRIMFASTQ_SCRIPT} {input.alltrimmed} 50 -stdout 2>/dev/null > {output.trimmed_50bp}
        """

# Genome mapping rules
rule bowtie_mapping:
    input:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq",
        index_files = expand(f"{DM6_BOWTIE_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    output:
        sam = RESULTS_DIR + "/bowtie/{sample}.sam"
    conda:
        "envs/bowtie.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/bowtie
        {BOWTIE_CMD} {DM6_BOWTIE_INDEX} -p {threads} -v 2 -k 1 -m 1 -t --sam-nh --best --strata -y --quiet {input.trimmed_50bp} > {output.sam}
        """

rule samtools_view:
    input:
        sam = RESULTS_DIR + "/bowtie/{sample}.sam",
        reference = DM6_REFERENCE
    output:
        bam = RESULTS_DIR + "/bowtie/{sample}.bam"
    shell:
        """
        # The patched bowtie with --sam-nh creates SAM files in a simplified format (8 fields instead of 11)
        # We need to convert to standard SAM format before old samtools-0.1.8 can process it
        python3 -c "
import sys
ref_file = '{input.reference}'
sam_file = '{input.sam}'

# Generate header
print('@HD\tVN:1.0\tSO:unsorted')
with open(ref_file, 'r') as f:
    lines = f.readlines()
    current_chr = None
    current_seq = []
    for line in lines:
        if line.startswith('>'):
            if current_chr:
                seq_len = sum(len(s.strip()) for s in current_seq)
                print(f'@SQ\tSN:{{current_chr}}\tLN:{{seq_len}}')
            current_chr = line[1:].strip().split()[0]
            current_seq = []
        else:
            current_seq.append(line.strip())
    if current_chr:
        seq_len = sum(len(s.strip()) for s in current_seq)
        print(f'@SQ\tSN:{{current_chr}}\tLN:{{seq_len}}')

# Convert patched bowtie format to standard SAM
# Input format: QNAME, strand, RNAME, POS, SEQ, QUAL, ?, mismatch_info
# Output format: QNAME, FLAG, RNAME, POS, MAPQ, CIGAR, RNEXT, PNEXT, TLEN, SEQ, QUAL
try:
    with open(sam_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            fields = line.split('\t')
            if len(fields) >= 6:
                qname = fields[0]
                strand = fields[1]
                rname = fields[2]
                pos = fields[3]
                seq = fields[4]
                qual = fields[5]
                
                # Convert strand to FLAG: '-' = 16 (reverse), '+' = 0 (forward)
                flag = '16' if strand == '-' else '0'
                # Calculate CIGAR from sequence length
                seq_len = len(seq)
                cigar = f'{{seq_len}}M'
                # Standard SAM fields
                mapq = '255'  # Unknown quality
                rnext = '*'
                pnext = '0'
                tlen = '0'
                
                # Print standard SAM line
                print(f'{{qname}}\t{{flag}}\t{{rname}}\t{{pos}}\t{{mapq}}\t{{cigar}}\t{{rnext}}\t{{pnext}}\t{{tlen}}\t{{seq}}\t{{qual}}')
except BrokenPipeError:
    # Handle pipe closure gracefully
    sys.stderr.close()
" | {SAMTOOLS_VIEW_CMD} view -bT {input.reference} - > {output.bam}
        """

rule samtools_sort_and_index:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.bam"
    output:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam.bai"
    shell:
        """
        cd {RESULTS_DIR}/bowtie && \
        {SAMTOOLS_SORT_CMD} sort $(basename {input.bam}) {wildcards.sample}.sorted_final && \
        {SAMTOOLS_INDEX_CMD} index {wildcards.sample}.sorted_final.bam
        """

rule remove_mitochondrial_reads:
    input:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam"
    output:
        no_mito_bam = RESULTS_DIR + "/bowtie/{sample}.mito_removed.bam"
    shell:
        """
        {SAMTOOLS_VIEW_CMD} view {input.sorted_bam} | egrep -v 'chrM' | {SAMTOOLS_VIEW_CMD} view -bT {DM6_REFERENCE} - -o {output.no_mito_bam}
        {SAMTOOLS_INDEX_CMD} index {output.no_mito_bam}
        """

rule samtools_sort_no_mito:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.mito_removed.bam"
    output:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam.bai"
    shell:
        """
        cd {RESULTS_DIR}/bowtie && \
        {SAMTOOLS_SORT_CMD} sort $(basename {input.bam}) {wildcards.sample}.no_mito_sorted && \
        {SAMTOOLS_INDEX_CMD} index {wildcards.sample}.no_mito_sorted.bam
        """

rule samtools_rmdup:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam"
    output:
        rmdup_bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam.bai"
    shell:
        """
        {SAMTOOLS_RMDUP_CMD} rmdup -s {input.bam} {output.rmdup_bam}
        {SAMTOOLS_INDEX_CMD} index {output.rmdup_bam}
        """

# Vector mapping rules
rule bowtie_vector_mapping:
    input:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq",
        index_files = expand(f"{VECTOR_42AB_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    output:
        sam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.sam"
    conda:
        "envs/bowtie.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/vector_mapping
        {BOWTIE_CMD} {VECTOR_42AB_INDEX} -p {threads} --chunkmbs 1024 -v 2 -k 1 -m 1 -t --sam-nh --best --strata -q {input.trimmed_50bp} > {output.sam}
        """

rule samtools_view_vector:
    input:
        sam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.sam",
        reference = VECTOR_42AB_REF
    output:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.bam"
    shell:
        """
        # The patched bowtie with --sam-nh creates SAM files in a simplified format (8 fields instead of 11)
        # We need to convert to standard SAM format before old samtools-0.1.8 can process it
        python3 -c "
import sys
ref_file = '{input.reference}'
sam_file = '{input.sam}'

# Generate header
with open(ref_file, 'r') as f:
    lines = f.readlines()
    ref_name = lines[0][1:].strip().split()[0]
    seq_len = sum(len(line.strip()) for line in lines[1:] if not line.startswith('>'))
    print('@HD\tVN:1.0\tSO:unsorted')
    print(f'@SQ\tSN:{{ref_name}}\tLN:{{seq_len}}')

# Convert patched bowtie format to standard SAM
# Input format: QNAME, strand, RNAME, POS, SEQ, QUAL, ?, mismatch_info
# Output format: QNAME, FLAG, RNAME, POS, MAPQ, CIGAR, RNEXT, PNEXT, TLEN, SEQ, QUAL
try:
    with open(sam_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            fields = line.split('\t')
            if len(fields) >= 6:
                qname = fields[0]
                strand = fields[1]
                rname = fields[2]
                pos = fields[3]
                seq = fields[4]
                qual = fields[5]
                
                # Convert strand to FLAG: '-' = 16 (reverse), '+' = 0 (forward)
                flag = '16' if strand == '-' else '0'
                # Calculate CIGAR from sequence length
                seq_len = len(seq)
                cigar = f'{{seq_len}}M'
                # Standard SAM fields
                mapq = '255'  # Unknown quality
                rnext = '*'
                pnext = '0'
                tlen = '0'
                
                # Print standard SAM line
                print(f'{{qname}}\t{{flag}}\t{{rname}}\t{{pos}}\t{{mapq}}\t{{cigar}}\t{{rnext}}\t{{pnext}}\t{{tlen}}\t{{seq}}\t{{qual}}')
except BrokenPipeError:
    # Handle pipe closure gracefully
    sys.stderr.close()
" | {SAMTOOLS_VIEW_CMD} view -F 4 -bT {input.reference} - > {output.bam}
        """

rule samtools_sort_and_index_vector:
    input:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.bam"
    output:
        sorted_bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam",
        bai = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam.bai"
    shell:
        """
        cd {RESULTS_DIR}/vector_mapping && \
        {SAMTOOLS_SORT_CMD} sort $(basename {input.bam}) {wildcards.sample}.vectoronly.dup && \
        {SAMTOOLS_INDEX_CMD} index {wildcards.sample}.vectoronly.dup.bam
        """

# Signal generation rules
rule make_bigwig:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam",
        chrom_sizes = DM6_CHROM_SIZES
    output:
        bigwig = RESULTS_DIR + "/bowtie/{sample}.bigwig"
    conda:
        "envs/python.yaml"
    shell:
        """
        python {MAKEWIGGLE_SCRIPT} --- {input.bam} {input.chrom_sizes} {output}.bg4 -notitle -uniqueBAM -RPM
        # Filter out negative coordinates and chromosomes not in chrom.sizes before converting to BigWig
        awk -F'\t' '{{if (NF >= 3 && $2 >= 0 && $3 >= 0 && $3 > $2) print}}' {output}.bg4 > {output}.bg4.filtered
        wigToBigWig -clip {output}.bg4.filtered {input.chrom_sizes} {output}
        rm {output}.bg4.filtered
        """

rule make_enrichment_track:
    input:
        chip_bam = f"{RESULTS_DIR}/bowtie/{CHIP_SAMPLE}.rmdup.bam",
        input_bam = f"{RESULTS_DIR}/bowtie/{INPUT_SAMPLE}.rmdup.bam",
        blacklist = DM6_BLACKLIST
    output:
        enrichment_bigwig = f"{RESULTS_DIR}/enrichment/Panx_GLKD_ChIP_input_1st_S1_R1_001_vs_Panx_GLKD_ChIP_input_2nd_S4_R1_001.enrichment.bigwig"
    conda:
        "envs/deeptools.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/enrichment
        bamCompare -b1 {input.chip_bam} -b2 {input.input_bam} -of bigwig -o {output.enrichment_bigwig} --binSize 10 -bl {input.blacklist} -p {threads}
        """

# Coverage analysis rules
rule bam_coverage:
    input:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam",
        chrom_sizes = GENOME_CHROM_SIZES
    output:
        total = RESULTS_DIR + "/coverage/{sample}.{binsize}.bg4",
        minus = RESULTS_DIR + "/coverage/{sample}.{binsize}.Minus.bg4",
        plus = RESULTS_DIR + "/coverage/{sample}.{binsize}.Plus.bg4"
    conda:
        "envs/deeptools.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/coverage
        EFFECTIVE_SIZE=$(awk '{{sum += $2}} END {{print sum}}' {input.chrom_sizes})
        bamCoverage -b {input.bam} -o {output.total} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE
        bamCoverage -b {input.bam} -o {output.minus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE --filterRNAstrand forward
        bamCoverage -b {input.bam} -o {output.plus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE --filterRNAstrand reverse
        """

rule chop_bedgraph:
    input:
        bg4 = RESULTS_DIR + "/coverage/{sample}.{binsize}.{strand}.bg4"
    output:
        chopped = RESULTS_DIR + "/coverage/{sample}.{binsize}.{strand}.bg4.chopped.bg4"
    conda:
        "envs/bedops.yaml"
    shell:
        """
        # Convert bg4 to BED format (add "." as 4th column) for bedmap
        awk -vOFS="\t" '{{ print $1, $2, $3, ".", $4 }}' {input.bg4} > signal.bed
        # Chop into uniform bins and interpolate scores from original bedgraph
        bedops --chop {wildcards.binsize} signal.bed | \
            bedmap --echo --echo-map-score - signal.bed | \
            sed -e 's/|/\t/g' > {output.chopped}
        rm signal.bed
        """

# Transposon analysis rules
rule bam_coverage_transposon:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam",
        chrom_sizes = GENOME_CHROM_SIZES
    output:
        total = RESULTS_DIR + "/transposon/{sample}.{binsize}.{transposon}.bg4",
        minus = RESULTS_DIR + "/transposon/{sample}.{binsize}.{transposon}.Minus.bg4",
        plus = RESULTS_DIR + "/transposon/{sample}.{binsize}.{transposon}.Plus.bg4"
    params:
        region = get_transposon_region
    conda:
        "envs/deeptools.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/transposon
        EFFECTIVE_SIZE=$(awk '{{sum += $2}} END {{print sum}}' {input.chrom_sizes})
        REGION={params.region}
        bamCoverage -b {input.bam} -o {output.total} -of bedgraph --binSize {wildcards.binsize} --region $REGION --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE
        bamCoverage -b {input.bam} -o {output.minus} -of bedgraph --binSize {wildcards.binsize} --region $REGION --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE --filterRNAstrand forward
        bamCoverage -b {input.bam} -o {output.plus} -of bedgraph --binSize {wildcards.binsize} --region $REGION --normalizeUsing RPGC --effectiveGenomeSize $EFFECTIVE_SIZE --filterRNAstrand reverse
        """

rule chop_bedgraph_transposon:
    input:
        bg4 = RESULTS_DIR + "/transposon/{sample}.{binsize}.{transposon}.{strand}.bg4"
    output:
        chopped = RESULTS_DIR + "/transposon/{sample}.{binsize}.{transposon}.{strand}.bg4.chopped.bg4"
    conda:
        "envs/bedops.yaml"
    shell:
        """
        # Convert bg4 to BED format (add "." as 4th column) for bedmap
        awk -vOFS="\t" '{{ print $1, $2, $3, ".", $4 }}' {input.bg4} > signal.bed
        # Chop into uniform bins and interpolate scores from original bedgraph
        bedops --chop {wildcards.binsize} signal.bed | \
            bedmap --echo --echo-map-score - signal.bed | \
            sed -e 's/|/\t/g' > {output.chopped}
        rm signal.bed
        """
