# ChIP-seq Analysis Pipeline (Snakemake)
# Based on Peng-He-Lab/Luo_2025_piRNA repository
# This workflow processes ChIP-seq data from raw FASTQ to BigWig visualization

# Load configuration
configfile: "config.yaml"

# ==============================================================================
# BACKWARD COMPATIBILITY LAYER
# ==============================================================================
# Support both old-style (references section) and new-style (genome section)
# configuration formats. If 'genome' section exists, use it; otherwise fall
# back to old 'references' section.
# ==============================================================================

if "genome" in config:
    # New format - use genome-agnostic configuration
    GENOME_VERSION = config["genome"]["version"]
    GENOME_SPECIES = config["genome"]["species"]
    
    # Expand path templates with genome version
    GENOME_FASTA = config["genome"]["fasta"].format(version=GENOME_VERSION)
    GENOME_BOWTIE_INDEX = config["genome"]["bowtie_index"].format(version=GENOME_VERSION)
    GENOME_CHROM_SIZES = config["genome"]["chrom_sizes"].format(version=GENOME_VERSION)
    
    # Optional blacklist file (not all genomes have this)
    if "blacklist" in config["genome"] and config["genome"]["blacklist"]:
        GENOME_BLACKLIST = config["genome"]["blacklist"].format(version=GENOME_VERSION)
    else:
        GENOME_BLACKLIST = None
    
    # GTF file for annotations
    if "gtf" in config["genome"]:
        GENOME_GTF = config["genome"]["gtf"].format(version=GENOME_VERSION)
    else:
        GENOME_GTF = None
else:
    # Old format - use legacy dm6-specific configuration
    GENOME_VERSION = "dm6"
    GENOME_SPECIES = "drosophila"
    GENOME_FASTA = config["references"]["dm6_fasta"]
    GENOME_BLACKLIST = config["references"]["dm6_blacklist"]
    GENOME_CHROM_SIZES = config["references"]["dm6_chrom_sizes"]
    GENOME_BOWTIE_INDEX = config["references"]["dm6_bowtie_index"]
    GENOME_GTF = None

# Legacy variable names for backward compatibility with existing code
DM6_REFERENCE = GENOME_FASTA
DM6_BLACKLIST = GENOME_BLACKLIST
DM6_CHROM_SIZES = GENOME_CHROM_SIZES
DM6_BOWTIE_INDEX = GENOME_BOWTIE_INDEX

# Extract configuration values
CHIP_SAMPLE = config["samples"]["chip"]
INPUT_SAMPLE = config["samples"]["input"]
SAMPLES = [CHIP_SAMPLE, INPUT_SAMPLE]

# Paths
RESULTS_DIR = config["output"]["results_dir"]
INPUT_DATA_DIR = config["input_data"]["data_dir"]

# Scripts
TRIMFASTQ_SCRIPT = config["scripts"]["trimfastq"]
MAKEWIGGLE_SCRIPT = config["scripts"]["makewiggle"]

# Vector files
VECTOR_42AB_INDEX = config["references"]["vector_42ab_index"]
VECTOR_42AB_REF = config["references"]["vector_42ab_fasta"]
VECTOR_20A_INDEX = config["references"]["vector_20a_index"]
VECTOR_20A_REF = config["references"]["vector_20a_fasta"]

# Adapter files
ADAPTERS_FILE = config["references"]["adapters_file"]

# Analysis parameters
BIN_SIZES = config["analysis"]["bin_sizes"]
TRANSPOSON_BIN_SIZES = config["analysis"]["transposon_bin_sizes"]

# Main rule - defines all outputs
rule all:
    input:
        # Quality control outputs
        expand(f"{RESULTS_DIR}/fastqc_trimmed/{{sample}}.alltrimmed_fastqc.html", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/trimmed_50bp/{{sample}}.fastq", sample=SAMPLES),

        # Genome mapping outputs
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.sorted_final.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.sorted_final.bam.bai", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.no_mito_sorted.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.rmdup.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.rmdup.bam.bai", sample=SAMPLES),

        # Vector mapping outputs
        expand(f"{RESULTS_DIR}/vector_mapping/{{sample}}.vectoronly.dup.bam", sample=SAMPLES),
        expand(f"{RESULTS_DIR}/vector_mapping/{{sample}}.vectoronly.dup.bam.bai", sample=SAMPLES),

        # Signal outputs
        expand(f"{RESULTS_DIR}/bowtie/{{sample}}.bigwig", sample=SAMPLES),

        # Enrichment analysis
        f"{RESULTS_DIR}/enrichment/Panx_GLKD_ChIP_input_1st_S1_R1_001_vs_Panx_GLKD_ChIP_input_2nd_S4_R1_001.enrichment.bigwig",

        # Coverage analysis
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.Minus.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/coverage/{{sample}}.{{binsize}}.Plus.bg4",
            sample=SAMPLES,
            binsize=BIN_SIZES,
        ),
        # Temporarily disabled chopped files due to disk space issues
        # expand(
        #     RESULTS_DIR + "/coverage/{sample}.{binsize}.Minus.bg4.chopped.bg4",
        #     sample=SAMPLES,
        #     binsize=BIN_SIZES,
        # ),
        # expand(
        #     RESULTS_DIR + "/coverage/{sample}.{binsize}.Plus.bg4.chopped.bg4",
        #     sample=SAMPLES,
        #     binsize=BIN_SIZES,
        # ),

        # Transposon analysis
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.42AB.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.42AB.Minus.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
        ),
        expand(
            f"{RESULTS_DIR}/transposon/{{sample}}.{{binsize}}.42AB.Plus.bg4",
            sample=SAMPLES,
            binsize=TRANSPOSON_BIN_SIZES,
        ),
        # 20A transposon analysis temporarily disabled - no generation rules present
        # expand(
        #     f"{RESULTS_DIR}/transposon/{{sample}.{{binsize}.20A.bg4",
        #     sample=SAMPLES,
        #     binsize=TRANSPOSON_BIN_SIZES,
        # ),
        # expand(
        #     f"{RESULTS_DIR}/transposon/{{sample}.{{binsize}.20A.Minus.bg4",
        #     sample=SAMPLES,
        #     binsize=TRANSPOSON_BIN_SIZES,
        # ),
        # expand(
        #     f"{RESULTS_DIR}/transposon/{{sample}.{{binsize}.20A.Plus.bg4",
        #     sample=SAMPLES,
        #     binsize=TRANSPOSON_BIN_SIZES,
        # )

# Index building rules - these generate indexes from source files
rule build_genome_bowtie_index:
    """Build bowtie index for the genome (genome-agnostic)"""
    input:
        genome_fa = GENOME_FASTA
    output:
        index_files = expand(f"{GENOME_BOWTIE_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {GENOME_BOWTIE_INDEX})
        bowtie-build {input.genome_fa} {GENOME_BOWTIE_INDEX}
        """

rule build_vector_42AB_index:
    input:
        vector_fa = VECTOR_42AB_REF
    output:
        index_files = expand(f"{VECTOR_42AB_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {VECTOR_42AB_INDEX})
        bowtie-build {input.vector_fa} {VECTOR_42AB_INDEX}
        """

rule build_vector_20A_index:
    input:
        vector_fa = VECTOR_20A_REF
    output:
        index_files = expand(f"{VECTOR_20A_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        mkdir -p $(dirname {VECTOR_20A_INDEX})
        bowtie-build {input.vector_fa} {VECTOR_20A_INDEX}
        """

rule generate_chrom_sizes:
    """Generate chromosome sizes file from genome FASTA (genome-agnostic)"""
    input:
        genome_fa = GENOME_FASTA
    output:
        chrom_sizes = GENOME_CHROM_SIZES
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        mkdir -p $(dirname {output.chrom_sizes})
        samtools faidx {input.genome_fa}
        cut -f1,2 {input.genome_fa}.fai > {output.chrom_sizes}
        """

# Quality control rules
rule fastqc_raw:
    input:
        fastq = f"{INPUT_DATA_DIR}/{{sample}}.fastq"
    output:
        html = RESULTS_DIR + "/fastqc_raw/{{sample}}_fastqc.html",
        zip = RESULTS_DIR + "/fastqc_raw/{{sample}}_fastqc.zip"
    conda:
        "envs/fastqc.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/fastqc_raw
        fastqc {input.fastq} -o {RESULTS_DIR}/fastqc_raw
        """

rule trim_adapters:
    input:
        fastq = f"{INPUT_DATA_DIR}/{{sample}}.fastq",
        adapters = ADAPTERS_FILE
    output:
        trimmed = RESULTS_DIR + "/trimmed/{sample}.trimmed.fastq"
    conda:
        "envs/cutadapt.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/trimmed
        cutadapt -a file:{input.adapters} -o {output.trimmed} {input.fastq}
        """

rule trimmomatic:
    input:
        fastq = RESULTS_DIR + "/trimmed/{sample}.trimmed.fastq"
    output:
        trimmed = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    conda:
        "envs/trimmomatic.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/trimmomatic
        trimmomatic SE {input.fastq} {output.trimmed} \
            ILLUMINACLIP:{ADAPTERS_FILE}:2:30:10 \
            LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:50
        """

rule fastqc_trimmed:
    input:
        fastq = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    output:
        html = RESULTS_DIR + "/fastqc_trimmed/{sample}.alltrimmed_fastqc.html",
        zip = RESULTS_DIR + "/fastqc_trimmed/{sample}.alltrimmed_fastqc.zip"
    conda:
        "envs/fastqc.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/fastqc_trimmed
        fastqc {input.fastq} -o {RESULTS_DIR}/fastqc_trimmed
        """

rule trim_to_50bp:
    input:
        alltrimmed = RESULTS_DIR + "/trimmomatic/{sample}.alltrimmed.fastq"
    output:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq"
    conda:
        "envs/python.yaml"
    shell:
        """
        mkdir -p $(dirname {output.trimmed_50bp})
        python {TRIMFASTQ_SCRIPT} {input.alltrimmed} 50 -stdout 2>/dev/null > {output.trimmed_50bp}
        """

# Genome mapping rules
rule bowtie_mapping:
    input:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq",
        index_files = expand(f"{DM6_BOWTIE_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    output:
        sam = RESULTS_DIR + "/bowtie/{sample}.sam"
    conda:
        "envs/bowtie.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/bowtie
        bowtie {DM6_BOWTIE_INDEX} -p {threads} -v 2 -k 1 -m 1 -t --sam --best --strata -y --quiet {input.trimmed_50bp} > {output.sam}
        """

rule samtools_view:
    input:
        sam = RESULTS_DIR + "/bowtie/{sample}.sam",
        reference = DM6_REFERENCE
    output:
        bam = RESULTS_DIR + "/bowtie/{sample}.bam"
    conda:
        "envs/samtools-0.1.12.yaml"
    shell:
        """
        samtools view -bT {input.reference} {input.sam} > {output.bam}
        """

rule samtools_sort_and_index:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.bam"
    output:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam.bai"
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        samtools sort -o {output.sorted_bam} {input.bam}
        samtools index {output.sorted_bam}
        """

rule remove_mitochondrial_reads:
    input:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.sorted_final.bam"
    output:
        no_mito_bam = RESULTS_DIR + "/bowtie/{sample}.mito_removed.bam"
    conda:
        "envs/samtools-0.1.16.yaml"
    shell:
        """
        samtools view {input.sorted_bam} | egrep -v 'chrM' | samtools view -bT {DM6_REFERENCE} - > {output.no_mito_bam}
        samtools index {output.no_mito_bam}
        """

rule samtools_sort_no_mito:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.mito_removed.bam"
    output:
        sorted_bam = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam.bai"
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        samtools sort -o {output.sorted_bam} {input.bam}
        samtools index {output.sorted_bam}
        """

rule samtools_rmdup:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.no_mito_sorted.bam"
    output:
        rmdup_bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam",
        bai = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam.bai"
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        samtools markdup {input.bam} {output.rmdup_bam}
        samtools index {output.rmdup_bam}
        """

# Vector mapping rules
rule bowtie_vector_mapping:
    input:
        trimmed_50bp = RESULTS_DIR + "/trimmed_50bp/{sample}.fastq",
        index_files = expand(f"{VECTOR_42AB_INDEX}.{{ext}}", ext=["1.ebwt", "2.ebwt", "3.ebwt", "4.ebwt", "rev.1.ebwt", "rev.2.ebwt"])
    output:
        sam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.sam"
    conda:
        "envs/bowtie.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/vector_mapping
        bowtie {VECTOR_42AB_INDEX} -p {threads} --chunkmbs 1024 -v 0 -a -m 1 -t --sam --best --strata -q {input.trimmed_50bp} > {output.sam}
        """

rule samtools_view_vector:
    input:
        sam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.sam",
        reference = VECTOR_42AB_REF
    output:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.bam"
    conda:
        "envs/samtools-0.1.12.yaml"
    shell:
        """
        samtools view -F 4 -bT {input.reference} {input.sam} > {output.bam}
        """

rule samtools_sort_and_index_vector:
    input:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.bam"
    output:
        sorted_bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam",
        bai = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam.bai"
    conda:
        "envs/samtools-1.16.1.yaml"
    shell:
        """
        samtools sort -o {output.sorted_bam} {input.bam}
        samtools index {output.sorted_bam}
        """

# Signal generation rules
rule make_bigwig:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam",
        chrom_sizes = DM6_CHROM_SIZES
    output:
        bigwig = RESULTS_DIR + "/bowtie/{sample}.bigwig"
    conda:
        "envs/python.yaml"
    shell:
        """
        python {MAKEWIGGLE_SCRIPT} --- {input.bam} {input.chrom_sizes} {output}.bg4 -notitle -uniqueBAM -RPM
        wigToBigWig {output}.bg4 {input.chrom_sizes} {output}
        """

rule make_enrichment_track:
    input:
        chip_bam = f"{RESULTS_DIR}/bowtie/{CHIP_SAMPLE}.rmdup.bam",
        input_bam = f"{RESULTS_DIR}/bowtie/{INPUT_SAMPLE}.rmdup.bam",
        blacklist = DM6_BLACKLIST
    output:
        enrichment_bigwig = f"{RESULTS_DIR}/enrichment/Panx_GLKD_ChIP_input_1st_S1_R1_001_vs_Panx_GLKD_ChIP_input_2nd_S4_R1_001.enrichment.bigwig"
    conda:
        "envs/deeptools.yaml"
    threads: config["processing"]["threads"]
    shell:
        """
        mkdir -p {RESULTS_DIR}/enrichment
        bamCompare -b1 {input.chip_bam} -b2 {input.input_bam} -of bigwig -o {output.enrichment_bigwig} --binSize 10 -bl {input.blacklist} -p {threads}
        """

# Coverage analysis rules
rule bam_coverage:
    input:
        bam = RESULTS_DIR + "/vector_mapping/{sample}.vectoronly.dup.bam"
    output:
        total = RESULTS_DIR + "/coverage/{sample}.{binsize}.bg4",
        minus = RESULTS_DIR + "/coverage/{sample}.{binsize}.Minus.bg4",
        plus = RESULTS_DIR + "/coverage/{sample}.{binsize}.Plus.bg4"
    conda:
        "envs/deeptools.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/coverage
        bamCoverage -b {input.bam} -o {output.total} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002
        bamCoverage -b {input.bam} -o {output.minus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002 --filterRNAstrand forward
        bamCoverage -b {input.bam} -o {output.plus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002 --filterRNAstrand reverse
        """

rule chop_bedgraph:
    input:
        bg4 = RESULTS_DIR + "/coverage/{sample}.{binsize}.{strand}.bg4"
    output:
        chopped = RESULTS_DIR + "/coverage/{sample}.{binsize}.{strand}.bg4.chopped.bg4"
    conda:
        "envs/bedops.yaml"
    shell:
        """
        bedops --chop {input.bg4} > {output.chopped}
        """

# Transposon analysis rules
rule bam_coverage_transposon:
    input:
        bam = RESULTS_DIR + "/bowtie/{sample}.rmdup.bam"
    output:
        total = RESULTS_DIR + "/transposon/{sample}.{binsize}.42AB.bg4",
        minus = RESULTS_DIR + "/transposon/{sample}.{binsize}.42AB.Minus.bg4",
        plus = RESULTS_DIR + "/transposon/{sample}.{binsize}.42AB.Plus.bg4"
    conda:
        "envs/deeptools.yaml"
    shell:
        """
        mkdir -p {RESULTS_DIR}/transposon
        bamCoverage -b {input.bam} -o {output.total} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002
        bamCoverage -b {input.bam} -o {output.minus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002 --filterRNAstrand forward
        bamCoverage -b {input.bam} -o {output.plus} --binSize {wildcards.binsize} --normalizeUsing RPGC --effectiveGenomeSize 143726002 --filterRNAstrand reverse
        """

rule chop_bedgraph_transposon:
    input:
        bg4 = RESULTS_DIR + "/transposon/{sample}.{binsize}.42AB.{strand}.bg4"
    output:
        chopped = RESULTS_DIR + "/transposon/{sample}.{binsize}.42AB.{strand}.bg4.chopped.bg4"
    conda:
        "envs/bedops.yaml"
    shell:
        """
        bedops --chop {input.bg4} > {output.chopped}
        """
